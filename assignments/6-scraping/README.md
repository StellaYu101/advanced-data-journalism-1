# Scraping assignment

Alrighty, the time has come for you to scrape a website on your own!

Your task will be to scrape some crash data from Missouri Highway Patrol site [here](https://www.mshp.dps.missouri.gov/HP68/SearchAction). Specifically, you will need to scrape all of the crashes reported on Oct. 31, 2017.

We've talked about breaking down a scraper into parts, so that's how we will approach this assignment. Rather than one large assignment, we're going to complete this in four parts, each due during one of the three subsequent class periods:

1. Setup: Import all libraries necessary to scrape the website and **be sure you can run the code on your machine without errors**. This might involve you using the virtual environment you set up in the beginning of class. **Due Wednesday, Oct. 30**.

2. Get the HTML and turn it into Soup: We're mixing steps 2 and 3 here, but the challenge will be getting the data from Oct. 31, 2017. How can you use what you learned about the Network tab and manipulating GET and POST parameters to get the page containing the crashes from that date? **Due Monday, Nov. 4**.

3. Scrape the data from the HTML: Use Python to find the correct elements on the page, extract the necessary data as text, and save them as a CSV file. **Due Wednesday, Nov. 6**.

At every step, you should upload the results of your code into a Github repository that I can see, then put a link to that repository in the [assignment spreadsheet](https://docs.google.com/spreadsheets/d/1omWnBWpSUVYUD10qOjZ3vYEj-YFYLbwXBJPpBahbDqU/edit#gid=0). I will look over your assignments before each class to be sure you turned them in, then I will go over the answers to each piece and answer questions before moving on to the next one.

The final product should be a single Python file containing a working scraper that accomplishes the task above.

Questions? Just ask.
